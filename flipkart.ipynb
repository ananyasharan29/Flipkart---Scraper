{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e90aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def random_alnum(length: int, uppercase: bool = False) -> str:\n",
    "    chars = string.ascii_uppercase + string.digits if uppercase else string.ascii_letters + string.digits\n",
    "    return ''.join(random.choices(chars, k=length))\n",
    "\n",
    "def random_cookie_header(num_pairs: int = 5, name_len: int = 8, value_len: int = 16) -> str:\n",
    "    pairs = [f\"{random_alnum(name_len)}={random_alnum(value_len)}\" for _ in range(num_pairs)]\n",
    "    return \"; \".join(pairs)\n",
    "\n",
    "def random_uuid4() -> str:\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "def random_fsn(length: int = 16) -> str:\n",
    "    return random_alnum(length, uppercase=True)\n",
    "\n",
    "def random_request_id(fsn: str = None, fsn_len: int = 16) -> str:\n",
    "    return f\"{random_uuid4()}.{fsn if fsn else random_fsn(fsn_len)}\"\n",
    "\n",
    "def fetch_product_json(product_id: str, pincode: str, proxies=None):\n",
    "    # generate random cookies\n",
    "    cookie_header = random_cookie_header(num_pairs=10, name_len=8, value_len=32)\n",
    "    cookies = dict(pair.split('=', 1) for pair in cookie_header.split('; '))\n",
    "\n",
    "    headers = {\n",
    "        'Accept': '*/*',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Content-Type': 'application/json',\n",
    "        'Origin': 'https://www.flipkart.com',\n",
    "        'Referer': 'https://www.flipkart.com/',\n",
    "        'Sec-Fetch-Dest': 'empty',\n",
    "        'Sec-Fetch-Mode': 'cors',\n",
    "        'Sec-Fetch-Site': 'same-site',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',\n",
    "        'X-User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36 FKUA/website/42/website/Desktop',\n",
    "        'sec-ch-ua': '\"Google Chrome\";v=\"137\", \"Chromium\";v=\"137\", \"Not/A)Brand\";v=\"24\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"Windows\"',\n",
    "        # 'Cookie': '...',\n",
    "    }\n",
    "    # inject random Cookie header and random Request-ID\n",
    "    headers['Cookie'] = cookie_header\n",
    "    headers['REQUEST-ID'] = random_request_id(fsn=product_id)\n",
    "\n",
    "    # 1) build the Flipkart product page URI for your JSON API\n",
    "    page_uri = (\n",
    "        \"/noise-colorfit-icon-2-1-8-display-bluetooth-calling-\"\n",
    "        f\"ai-voice-assistant-smartwatch/p/itm8229e27c1df28?pid={product_id}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    payload = {\n",
    "        \"pageUri\": page_uri,\n",
    "        \"locationContext\": {\"pincode\": str(pincode)},\n",
    "        \"isReloadRequest\": True\n",
    "    }\n",
    "\n",
    "\n",
    "    # 4) POST to the Flipkart JSON API\n",
    "    session = requests.Session()\n",
    "    max_retries = 2\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        resp = session.post(\n",
    "            \"https://2.rome.api.flipkart.com/api/4/page/fetch\",\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            cookies=cookies,\n",
    "            proxies=proxies or {},\n",
    "            timeout=30,\n",
    "            verify='zyte-ca.crt'\n",
    "        )\n",
    "\n",
    "\n",
    "        # handle Zyte/520 Temporary errors\n",
    "        if resp.status_code == 520:\n",
    "            retry_after = int(resp.headers.get(\"Retry-After\", 60))\n",
    "            print(f\"[{attempt}] 520 → retrying in {retry_after}s…\")\n",
    "            time.sleep(retry_after)\n",
    "            continue\n",
    "        resp.raise_for_status()\n",
    "        break\n",
    "\n",
    "    data = resp.json()\n",
    "\n",
    "\n",
    "    with open(f\"Flipkart_outputs/{product_id}_{pincode}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "    return data\n",
    "\n",
    "# function to extract required data points from the raw JSON\n",
    "def extract_product_data(raw_json: dict, product_id: str, pincode: str) -> dict:\n",
    "    page_data = raw_json.get('RESPONSE', {}).get('pageData', {})\n",
    "    # Title and length\n",
    "    try:\n",
    "        title = page_data.get('pageContext', {}).get('seo', {}).get('title', '')\n",
    "    except:\n",
    "        title = ''\n",
    "    \n",
    "    \n",
    "    title_len = len(title)\n",
    "    # Pricing details\n",
    "    pricing = page_data.get('pricing', {})\n",
    "    try:\n",
    "        mrp = page_data.get('pageContext', {}).get('fdpEventTracking', {}).get('events', {}).get('psi', {}).get('ppd', {}).get('mrp')\n",
    "    except:\n",
    "        mrp = None\n",
    "    try:\n",
    "        live_price = page_data.get('paginationContextMap', {}).get('nps', {}).get('pricing', {})\n",
    "    except:\n",
    "        live_price = ''\n",
    "    \n",
    "    # Availability status\n",
    "    try:\n",
    "        availability = page_data.get('pageContext', {}).get('fdpEventTracking', {}).get('events', {}).get('psi', {}).get('pls', {}).get('isAvailable')\n",
    "    except:\n",
    "        availability = None\n",
    "    if availability:\n",
    "        availability = 'Yes'\n",
    "    else:\n",
    "        availability = 'No'\n",
    "    \n",
    "    \n",
    "    # Deal tag from special price\n",
    "    try:\n",
    "        deal_tag = page_data.get('pageContext', {}).get('fdpEventTracking', {}).get('events', {}).get('psi', {}).get('ppd', {}).get('isSpecialPrice')\n",
    "    except:\n",
    "        deal_tag = None\n",
    "    if deal_tag:\n",
    "        deal_tag = 'Yes'\n",
    "    else:\n",
    "        deal_tag = 'No'\n",
    "\n",
    "    \n",
    "    # RESPONSE.slots[10].widget.data.offerInfo.value.offerGroups[0].offers[1].value.tags\n",
    "    for price in pricing.get('prices', []):\n",
    "        if price.get('priceType') == 'SPECIAL_PRICE':\n",
    "            deal_tag = price.get('name')\n",
    "            break\n",
    "    \n",
    "    # Dynamic highlights extraction\n",
    "    bullet_points = None\n",
    "    try:\n",
    "        # Search through all slots to find highlights\n",
    "        slots = raw_json.get('RESPONSE', {}).get('slots', [])\n",
    "        for slot in slots:\n",
    "            if isinstance(slot, dict):\n",
    "                widget = slot.get('widget', {})\n",
    "                if isinstance(widget, dict):\n",
    "                    data = widget.get('data', {})\n",
    "                    if isinstance(data, dict):\n",
    "                        # Check for highlights in the data\n",
    "                        highlights = data.get('highlights', {})\n",
    "                        if isinstance(highlights, dict):\n",
    "                            value = highlights.get('value', {})\n",
    "                            if isinstance(value, dict):\n",
    "                                text = value.get('text')\n",
    "                                if text:\n",
    "                                    bullet_points = len(text)\n",
    "                                    break\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting highlights: {e}\")\n",
    "        bullet_points = None\n",
    "    \n",
    "        \n",
    "    # Catalog media counts\n",
    "    try:\n",
    "        catalog_images = page_data.get('pageContext', {}).get('fdpEventTracking', {}).get('events', {}).get('psi', {}).get('pas', {}).get('imagesCount')\n",
    "    except:\n",
    "        catalog_images = None\n",
    "    try:\n",
    "        catalog_videos = page_data.get('pageContext', {}).get('fdpEventTracking', {}).get('events', {}).get('psi', {}).get('pas', {}).get('videosCount') or 0\n",
    "    except:\n",
    "        catalog_videos = None\n",
    "    # Estimated delivery dates\n",
    "\n",
    "    try:\n",
    "        edd = page_data.get('pageContext', {}).get('trackingDataV2', {}).get('slaText')\n",
    "    except Exception as e:\n",
    "        edd = None\n",
    "    edd_fresh = None\n",
    "    # Number of variations\n",
    "    variations = len(page_data.get('swatchInfo', {}).get('mandatorySwatchAttributes', []))\n",
    "    # Ratings breakdown\n",
    "    try:    \n",
    "        one_star = page_data.get('pageContext', {}).get('fdpEventTracking', {}).get('commonContext', {}).get('pr', {}).get('individualRatingsCount', [])[4].get('ratingCount')\n",
    "        two_star = page_data.get('pageContext', {}).get('fdpEventTracking', {}).get('commonContext', {}).get('pr', {}).get('individualRatingsCount', [])[3].get('ratingCount')\n",
    "        three_star = page_data.get('pageContext', {}).get('fdpEventTracking', {}).get('commonContext', {}).get('pr', {}).get('individualRatingsCount', [])[2].get('ratingCount')\n",
    "        total_ratings = page_data.get('pageContext', {}).get('fdpEventTracking', {}).get('commonContext', {}).get('pr', {}).get('ratingsCount')\n",
    "    except:\n",
    "        one_star = None\n",
    "        two_star = None\n",
    "        three_star = None\n",
    "        total_ratings = None\n",
    "\n",
    "    try:\n",
    "        average_rating = page_data.get('pageContext', {}).get('fdpEventTracking', {}).get('commonContext', {}).get('pr', {}).get('rating')\n",
    "    except:\n",
    "        average_rating = None\n",
    "    # BSR not provided\n",
    "    sub_cat_bsr = None\n",
    "    cat_bsr = None\n",
    "    # Seller information\n",
    "\n",
    "    try:\n",
    "        sold_by = page_data.get('pageContext', {}).get('trackingDataV2', {}).get('sellerName')\n",
    "    except:\n",
    "        sold_by = None\n",
    "\n",
    "    # Product description text from TEXT widget - also make this dynamic\n",
    "    description = 'No'\n",
    "    try:\n",
    "        # Search through all slots to find description\n",
    "        slots = raw_json.get('RESPONSE', {}).get('slots', [])\n",
    "        for slot in slots:\n",
    "            if isinstance(slot, dict):\n",
    "                widget = slot.get('widget', {})\n",
    "                if isinstance(widget, dict):\n",
    "                    data = widget.get('data', {})\n",
    "                    if isinstance(data, dict):\n",
    "                        renderable_components = data.get('renderableComponents', [])\n",
    "                        if isinstance(renderable_components, list) and renderable_components:\n",
    "                            for component in renderable_components:\n",
    "                                if isinstance(component, dict):\n",
    "                                    value = component.get('value', {})\n",
    "                                    if isinstance(value, dict):\n",
    "                                        text = value.get('text')\n",
    "                                        if text and len(text) > 50:  # Assume description is longer than 50 chars\n",
    "                                            description = 'Yes'\n",
    "                                            break\n",
    "                        if description == 'Yes':\n",
    "                            break\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting description: {e}\")\n",
    "        description = 'No'\n",
    "\n",
    "    # Optional fields not in JSON\n",
    "    bxgy = 'No'\n",
    "    try:\n",
    "        slots = raw_json.get('RESPONSE', {}).get('slots', [])\n",
    "        for slot in slots:\n",
    "            widget = slot.get('widget', {})\n",
    "            if not isinstance(widget, dict):\n",
    "                continue\n",
    "            data = widget.get('data', {})\n",
    "            if not isinstance(data, dict) or 'offerInfo' not in data:\n",
    "                continue\n",
    "            offer_info = data.get('offerInfo', {}).get('value', {})\n",
    "            for group in offer_info.get('offerGroups', []):\n",
    "                for offer in group.get('offers', []):\n",
    "                    tracking = offer.get('action', {}).get('tracking', {})\n",
    "                    tags = offer.get('value', {}).get('tags', [])\n",
    "                    if tracking.get('offerType') == 'Combo Offer' or 'Combo Offer' in tags:\n",
    "                        bxgy = 'Yes'\n",
    "                        break\n",
    "                if bxgy == 'Yes':\n",
    "                    break\n",
    "            if bxgy == 'Yes':\n",
    "                break\n",
    "    except Exception:\n",
    "        bxgy = 'No'\n",
    "\n",
    "    # Detect A+ featureSetList presence\n",
    "    a_plus = 'No'\n",
    "    try:\n",
    "        slots = raw_json.get('RESPONSE', {}).get('slots', [])\n",
    "        for slot in slots:\n",
    "            widget = slot.get('widget', {})\n",
    "            if not isinstance(widget, dict):\n",
    "                continue\n",
    "            data = widget.get('data', {})\n",
    "            if not isinstance(data, dict):\n",
    "                continue\n",
    "            if 'featureSetList' in data:\n",
    "                a_plus = 'Yes'\n",
    "                break\n",
    "    except Exception:\n",
    "        a_plus = 'No'\n",
    "\n",
    "    sns = 'NA'\n",
    "    # Detect coupon offers in raw JSON\n",
    "    coupon = 'No'\n",
    "    try:\n",
    "        slots = raw_json.get('RESPONSE', {}).get('slots', [])\n",
    "        for slot in slots:\n",
    "            widget = slot.get('widget', {})\n",
    "            if not isinstance(widget, dict):\n",
    "                continue\n",
    "            data = widget.get('data', {})\n",
    "            if not isinstance(data, dict) or 'offerInfo' not in data:\n",
    "                continue\n",
    "            offer_info = data.get('offerInfo', {}).get('value', {})\n",
    "            for group in offer_info.get('offerGroups', []):\n",
    "                for offer in group.get('offers', []):\n",
    "                    description1 = offer.get('value', {}).get('description', '')\n",
    "                    if isinstance(description1, str) and 'coupon' in description1.lower():\n",
    "                        coupon = 'Yes'\n",
    "                        break\n",
    "                if coupon == 'Yes':\n",
    "                    break\n",
    "            if coupon == 'Yes':\n",
    "                break\n",
    "    except Exception:\n",
    "        coupon = 'No'\n",
    "    # Number of other sellers\n",
    "    try:\n",
    "        seller_count = page_data.get('pageContext', {}).get('trackingDataV2', {}).get('sellerCount')\n",
    "        other_sellers = seller_count - 1 if seller_count is not None else None\n",
    "    except:\n",
    "        other_sellers = None\n",
    "    return {\n",
    "        \"Product ID\": product_id,\n",
    "        \"Pincode\": pincode,\n",
    "        \"Title Length\": title_len,\n",
    "        \"MRP\": mrp,\n",
    "        \"Live Price\": live_price,\n",
    "        \"Availability\": availability,\n",
    "        \"Deal Tag\": deal_tag,\n",
    "        \"Title\": title,\n",
    "        \"Bullet Points\": bullet_points,\n",
    "        \"Count of Catalog Images\": catalog_images,\n",
    "        \"Videos in Catalog\": catalog_videos,\n",
    "        \"EDD\": edd,\n",
    "        \"EDD_Fresh\": edd_fresh,\n",
    "        \"Number of Variations\": variations,\n",
    "        \"3 Star Ratings\": three_star,\n",
    "        \"2 Star Ratings\": two_star,\n",
    "        \"1 Star Ratings\": one_star,\n",
    "        \"Total Ratings\": total_ratings,\n",
    "        \"Ratings\": average_rating,\n",
    "        \"Sub-Category BSR\": sub_cat_bsr,\n",
    "        \"Category BSR\": cat_bsr,\n",
    "        \"Sold By\": sold_by,\n",
    "        \"Description\": description,\n",
    "        \"BXGY\": bxgy,\n",
    "        \"A+\": a_plus,\n",
    "        \"SNS\": sns,\n",
    "        \"Coupon\": coupon,\n",
    "        \"Number of Other Sellers\": other_sellers\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # example tied into your Excel loop\n",
    "    df_urls = pd.read_excel(\"Hygiene Input Master (HIM).xlsx\", sheet_name=\"Oshea - Flipkart Rule\")\n",
    "    df_pins = pd.read_excel(\"Hygiene Input Master (HIM).xlsx\", sheet_name=\"Pincodes\")\n",
    "\n",
    "    proxies = {\n",
    "        \"http\":  \"http://ef8ca12adcf240c5b9691d1c821bc333:@api.zyte.com:8011/\",\n",
    "        \"https\": \"http://ef8ca12adcf240c5b9691d1c821bc333:@api.zyte.com:8011/\"\n",
    "    }\n",
    "\n",
    "    output_dir = \"Flipkart_outputs\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Build set of already scraped (product_id, pincode) pairs\n",
    "    already_scraped = set()\n",
    "    for fname in os.listdir(output_dir):\n",
    "        if fname.endswith(\".json\"):\n",
    "            parts = fname.split(\"_\")\n",
    "            if len(parts) >= 2:\n",
    "                product_id = parts[0]\n",
    "                pincode = parts[1].replace('.json', '')  # Remove .json extension\n",
    "                already_scraped.add((product_id, pincode))\n",
    "\n",
    "\n",
    "    result = []\n",
    "    for files in os.listdir(output_dir):\n",
    "        if files.endswith(\".json\"):\n",
    "            with open(os.path.join(output_dir, files), \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            record = extract_product_data(data, files.split(\"_\")[0], files.split(\"_\")[1])\n",
    "            result.append(record)\n",
    "    df_result = pd.DataFrame(result)\n",
    "    df_result.to_csv(\"Flipkart_outputs/Flipkart_output.csv\", index=False)\n",
    "\n",
    "\n",
    "    # For Testing\n",
    "    \n",
    "    # pid=\"SMPGKDG7CH65HDZD\"\n",
    "    # pin=\"40013\"\n",
    "    # data = fetch_product_json(pid, pin, proxies)\n",
    "    # record = extract_product_data(data,pid,pin)\n",
    "    # print(record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
